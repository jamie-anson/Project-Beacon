---
title: Work Packages & Milestones
---

## Work Packages and Milestones

### Current Status
- **Phase 1 Completed**: Initial setup and integration with Golem have been successfully completed. The first tasks have been dispatched and executed on Golem.
- **Phase 2 In Progress**: Development of the IPFS-based transparency layer and integration of attester monitoring tools are underway.
- **Phase 3 Pending**: Community engagement and adoption efforts are planned for the upcoming phase, focusing on launching the public pilot and enhancing researcher UX.

### M1: Initial Setup and Integration (Month 1)
1. **Production Phase 0**: Initial Setup and Integration
   - Establish Golem integration and initial job specifications.
   - Set up Docker packaging and task dispatch system.
   - Milestone: Successful dispatch and execution of first tasks on Golem.

### M2: Vertical Slice (Month 1–2)
- **Production Phase 1**: Establish foundational components and demonstrate single-region execution.
- Single‑region execution on Golem
- Centralized AI API integration (ChatGPT, Gemini, Claude) with regional routing
- Hybrid comparison framework for decentralized vs centralized AI responses
- Publish IPFS bundles + Merkle root
- Portal shows root/proof + live activity
- Deliverables: repo, docs, demo

### M3: Transparency and Verification Tools (Month 2-3)
2. **Production Phase 1**: Transparency and Verification Tools
   - Develop IPFS-based transparency layer and proof endpoints.
   - Integrate attester monitoring tools for real-time progress tracking.
   - Milestone: Publicly accessible proofs and real-time monitoring dashboard.

### M4: Multi‑Region + Diff Engine (Month 3–4)
- **Production Phase 2**: Expand to multi-region execution and incorporate diff engine.
- ≥3 regions, orchestrated with retries/backoff
- Output comparison + diff visualizations
- Result aggregator + dashboards
- Deliverables: region manager, diff reports

### M5: Benchmark Suite Expansion (Month 4-5)
3. **Production Phase 2**: Benchmark Suite Expansion
   - Expand LLM benchmark suite to cover additional AI behaviors.
   - Enhance evaluation metrics for bias detection and output drift.
   - Milestone: Comprehensive benchmark results with actionable insights.

### M6: Public Pilot + Researcher UX (Month 5–6)
- **Production Phase 3**: Launch public pilot and enhance researcher user experience.
- Stable portal, public datasets, APIs for researchers
- Tutorials, notebooks, reproducibility guide
- Hosted demo + KPI report

### M7: Community Engagement and Adoption (Month 6)
4. **Production Phase 3**: Community Engagement and Adoption
   - Launch portal UI for community access and engagement.
   - Onboard researchers and collect feedback for improvements.
   - Milestone: Active community participation and feedback loop established.

Acceptance criteria per milestone: tagged release, demo, docs, reproducible run.
